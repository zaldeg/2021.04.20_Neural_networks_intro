{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0f7c604d00f38437f4df57123c10451e0676060e1a3eca5c56f25a4495d595057",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "f7c604d00f38437f4df57123c10451e0676060e1a3eca5c56f25a4495d595057"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import boston_housing\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers.experimental.preprocessing import Normalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "source": [
    "- CRIM     per capita crime rate by town\n",
    "- ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "- INDUS    proportion of non-retail business acres per town\n",
    "- CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
    "- NOX      nitric oxides concentration (parts per 10 million)\n",
    "- RM       average number of rooms per dwelling\n",
    "- AGE      proportion of owner-occupied units built prior to 1940\n",
    "- DIS      weighted distances to five Boston employment centres\n",
    "- RAD      index of accessibility to radial highways\n",
    "- TAX      full-value property-tax rate per $10,000\n",
    "- PTRATIO  pupil-teacher ratio by town\n",
    "- B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "- LSTAT    % lower status of the population\n",
    "- MEDV     Median value of owner-occupied homes in $1000's"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_nn(X_train, y_train, cv=5, activators=['relu'], losses=['mae'], optimizers=['Adam'], shapes=[[13,6,1]]):\n",
    "    '''\n",
    "    Input:\n",
    "        X_train, y_train\n",
    "        cv - number of model runs\n",
    "        activators - list of activators names\n",
    "        losses - list of losses names\n",
    "        optimizers - list of optimizers names\n",
    "        shapes - list of neural networks shapes\n",
    "    Output:\n",
    "        global_result - list of mean R2_score with std for every model runned cv times, looks like:\n",
    "            [[optimizer, activation, loss, shape, (R2_mean, R2_std)]]\n",
    "    '''\n",
    "\n",
    "    global_result = []\n",
    "    for optimizer in optimizers:\n",
    "        for activation in activators:\n",
    "            for loss in losses:\n",
    "                for shape in shapes:\n",
    "                    result = []\n",
    "                    print(optimizer, activation, loss, shape)\n",
    "                    for i in range(cv):\n",
    "                        model_reg = Sequential()\n",
    "                        model_reg.add(Dense(shape[0], activation=activation, input_shape=(13,)))\n",
    "                        for layer in range(1, len(shape) - 1):\n",
    "                            model_reg.add(Dense(shape[layer], activation=activation))\n",
    "                        model_reg.add(Dense(1, activation=activation))\n",
    "                        model_reg.compile(\n",
    "                                    optimizer=optimizer,\n",
    "                                    loss=loss,\n",
    "                                    metrics=[loss]\n",
    "                                )\n",
    "                        model_reg.fit(\n",
    "                                X_train,\n",
    "                                y_train,\n",
    "                                epochs=200,\n",
    "                                batch_size=20, \n",
    "                                validation_split=0.2,\n",
    "                                verbose=False)\n",
    "                        y_pred = model_reg.predict(X_test).flatten()\n",
    "                        if not np.isnan(y_pred.sum()):\n",
    "                            result.append(r2_score(y_test, y_pred))\n",
    "                        else:\n",
    "                            result.append(-10)\n",
    "                    global_result.append([optimizer, activation, loss, shape, (np.mean(result), np.std(result))])\n",
    "    return global_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalization()\n",
    "normalizer.adapt(X_train)\n",
    "X_train = normalizer(X_train)\n",
    "X_test = normalizer(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg = Sequential([\n",
    "    Dense(13, activation='relu', input_shape=(13,)),\n",
    "    Dense(6, activation='relu'),\n",
    "    Dense(1, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg.compile(optimizer='SGD',\n",
    "                     loss='mse',\n",
    "                     metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 13)                182       \n_________________________________________________________________\ndense_1 (Dense)              (None, 6)                 84        \n_________________________________________________________________\ndense_2 (Dense)              (None, 1)                 7         \n=================================================================\nTotal params: 273\nTrainable params: 273\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_reg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "17/17 [==============================] - 0s 9ms/step - loss: 299.4165 - mse: 299.4165 - val_loss: 114.1647 - val_mse: 114.1647\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ed29032d30>"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "model_reg.fit(X_train, y_train,\n",
    "  epochs=1,\n",
    "  batch_size=20, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "np.isnan(y_pred.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-0.41795448539080104"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Adam relu mae [13, 6, 1]\n",
      "Adam relu mae [50, 30, 1]\n",
      "Adam relu mae [13, 8, 5, 3, 1]\n",
      "Adam relu mse [13, 6, 1]\n",
      "Adam relu mse [50, 30, 1]\n",
      "Adam relu mse [13, 8, 5, 3, 1]\n",
      "Adam selu mae [13, 6, 1]\n",
      "Adam selu mae [50, 30, 1]\n",
      "Adam selu mae [13, 8, 5, 3, 1]\n",
      "Adam selu mse [13, 6, 1]\n",
      "Adam selu mse [50, 30, 1]\n",
      "Adam selu mse [13, 8, 5, 3, 1]\n",
      "Adam linear mae [13, 6, 1]\n",
      "Adam linear mae [50, 30, 1]\n",
      "Adam linear mae [13, 8, 5, 3, 1]\n",
      "Adam linear mse [13, 6, 1]\n",
      "Adam linear mse [50, 30, 1]\n",
      "Adam linear mse [13, 8, 5, 3, 1]\n",
      "RMSprop relu mae [13, 6, 1]\n",
      "RMSprop relu mae [50, 30, 1]\n",
      "RMSprop relu mae [13, 8, 5, 3, 1]\n",
      "RMSprop relu mse [13, 6, 1]\n",
      "RMSprop relu mse [50, 30, 1]\n",
      "RMSprop relu mse [13, 8, 5, 3, 1]\n",
      "RMSprop selu mae [13, 6, 1]\n",
      "RMSprop selu mae [50, 30, 1]\n",
      "RMSprop selu mae [13, 8, 5, 3, 1]\n",
      "RMSprop selu mse [13, 6, 1]\n",
      "RMSprop selu mse [50, 30, 1]\n",
      "RMSprop selu mse [13, 8, 5, 3, 1]\n",
      "RMSprop linear mae [13, 6, 1]\n",
      "RMSprop linear mae [50, 30, 1]\n",
      "RMSprop linear mae [13, 8, 5, 3, 1]\n",
      "RMSprop linear mse [13, 6, 1]\n",
      "RMSprop linear mse [50, 30, 1]\n",
      "RMSprop linear mse [13, 8, 5, 3, 1]\n",
      "SGD relu mae [13, 6, 1]\n",
      "SGD relu mae [50, 30, 1]\n",
      "SGD relu mae [13, 8, 5, 3, 1]\n",
      "SGD relu mse [13, 6, 1]\n",
      "SGD relu mse [50, 30, 1]\n",
      "SGD relu mse [13, 8, 5, 3, 1]\n",
      "SGD selu mae [13, 6, 1]\n",
      "SGD selu mae [50, 30, 1]\n",
      "SGD selu mae [13, 8, 5, 3, 1]\n",
      "SGD selu mse [13, 6, 1]\n",
      "SGD selu mse [50, 30, 1]\n",
      "SGD selu mse [13, 8, 5, 3, 1]\n",
      "SGD linear mae [13, 6, 1]\n",
      "SGD linear mae [50, 30, 1]\n",
      "SGD linear mae [13, 8, 5, 3, 1]\n",
      "SGD linear mse [13, 6, 1]\n",
      "SGD linear mse [50, 30, 1]\n",
      "SGD linear mse [13, 8, 5, 3, 1]\n",
      "Wall time: 29min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "models_result = fit_nn(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    cv=5,\n",
    "    activators=['relu', 'selu', 'linear'], \n",
    "    optimizers=['Adam', 'RMSprop', 'SGD'],\n",
    "    losses=['mae', 'mse'],\n",
    "    shapes=[[13,6,1], [50,30,1],[13,8,5,3,1]],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   optimizer activation loss      layers_shape  \\\n",
       "24   RMSprop       selu  mae        [13, 6, 1]   \n",
       "18   RMSprop       relu  mae        [13, 6, 1]   \n",
       "46       SGD       selu  mse       [50, 30, 1]   \n",
       "0       Adam       relu  mae        [13, 6, 1]   \n",
       "49       SGD     linear  mae       [50, 30, 1]   \n",
       "26   RMSprop       selu  mae  [13, 8, 5, 3, 1]   \n",
       "14      Adam     linear  mae  [13, 8, 5, 3, 1]   \n",
       "30   RMSprop     linear  mae        [13, 6, 1]   \n",
       "31   RMSprop     linear  mae       [50, 30, 1]   \n",
       "32   RMSprop     linear  mae  [13, 8, 5, 3, 1]   \n",
       "12      Adam     linear  mae        [13, 6, 1]   \n",
       "13      Adam     linear  mae       [50, 30, 1]   \n",
       "2       Adam       relu  mae  [13, 8, 5, 3, 1]   \n",
       "9       Adam       selu  mse        [13, 6, 1]   \n",
       "22   RMSprop       relu  mse       [50, 30, 1]   \n",
       "27   RMSprop       selu  mse        [13, 6, 1]   \n",
       "10      Adam       selu  mse       [50, 30, 1]   \n",
       "33   RMSprop     linear  mse        [13, 6, 1]   \n",
       "4       Adam       relu  mse       [50, 30, 1]   \n",
       "34   RMSprop     linear  mse       [50, 30, 1]   \n",
       "17      Adam     linear  mse  [13, 8, 5, 3, 1]   \n",
       "15      Adam     linear  mse        [13, 6, 1]   \n",
       "48       SGD     linear  mae        [13, 6, 1]   \n",
       "35   RMSprop     linear  mse  [13, 8, 5, 3, 1]   \n",
       "16      Adam     linear  mse       [50, 30, 1]   \n",
       "44       SGD       selu  mae  [13, 8, 5, 3, 1]   \n",
       "29   RMSprop       selu  mse  [13, 8, 5, 3, 1]   \n",
       "43       SGD       selu  mae       [50, 30, 1]   \n",
       "19   RMSprop       relu  mae       [50, 30, 1]   \n",
       "1       Adam       relu  mae       [50, 30, 1]   \n",
       "3       Adam       relu  mse        [13, 6, 1]   \n",
       "36       SGD       relu  mae        [13, 6, 1]   \n",
       "28   RMSprop       selu  mse       [50, 30, 1]   \n",
       "21   RMSprop       relu  mse        [13, 6, 1]   \n",
       "42       SGD       selu  mae        [13, 6, 1]   \n",
       "40       SGD       relu  mse       [50, 30, 1]   \n",
       "6       Adam       selu  mae        [13, 6, 1]   \n",
       "50       SGD     linear  mae  [13, 8, 5, 3, 1]   \n",
       "7       Adam       selu  mae       [50, 30, 1]   \n",
       "45       SGD       selu  mse        [13, 6, 1]   \n",
       "8       Adam       selu  mae  [13, 8, 5, 3, 1]   \n",
       "11      Adam       selu  mse  [13, 8, 5, 3, 1]   \n",
       "25   RMSprop       selu  mae       [50, 30, 1]   \n",
       "38       SGD       relu  mae  [13, 8, 5, 3, 1]   \n",
       "37       SGD       relu  mae       [50, 30, 1]   \n",
       "39       SGD       relu  mse        [13, 6, 1]   \n",
       "41       SGD       relu  mse  [13, 8, 5, 3, 1]   \n",
       "20   RMSprop       relu  mae  [13, 8, 5, 3, 1]   \n",
       "23   RMSprop       relu  mse  [13, 8, 5, 3, 1]   \n",
       "5       Adam       relu  mse  [13, 8, 5, 3, 1]   \n",
       "47       SGD       selu  mse  [13, 8, 5, 3, 1]   \n",
       "51       SGD     linear  mse        [13, 6, 1]   \n",
       "52       SGD     linear  mse       [50, 30, 1]   \n",
       "53       SGD     linear  mse  [13, 8, 5, 3, 1]   \n",
       "\n",
       "                               R2_score, R2_std  \n",
       "24   (0.7971420146721825, 0.023071709866071273)  \n",
       "18    (0.7905222860665662, 0.00666282304786063)  \n",
       "46    (0.7889368367335818, 0.04818958757485916)  \n",
       "0    (0.7873722926195287, 0.018833544419624967)  \n",
       "49    (0.7810966945571922, 0.00767961795034878)  \n",
       "26     (0.7775766646973096, 0.0491364572776173)  \n",
       "14  (0.7714796512416612, 0.0037570931662666562)  \n",
       "30    (0.7710631248033433, 0.01189962406137452)  \n",
       "31   (0.7688738094850047, 0.013713705773164435)  \n",
       "32   (0.7687810269385315, 0.010028637921486842)  \n",
       "12  (0.7668250625844604, 0.0038849891009697514)  \n",
       "13    (0.765599709625201, 0.010817962332270531)  \n",
       "2    (0.7616890051110026, 0.039455245070751044)  \n",
       "9    (0.7611727642963285, 0.019980520258177387)  \n",
       "22   (0.7584940836070853, 0.025270562807730886)  \n",
       "27    (0.7535051307230377, 0.03212190837906234)  \n",
       "10    (0.7367711127523142, 0.03285601501991992)  \n",
       "33   (0.7300046759942432, 0.013012323415112704)  \n",
       "4     (0.7295969412973518, 0.02376057417085283)  \n",
       "34    (0.7278543129695378, 0.02364931628676182)  \n",
       "17  (0.7254046705018851, 0.0027960706866333174)  \n",
       "15   (0.7247156959878326, 0.004706926457964261)  \n",
       "48    (0.7245256275966104, 0.04845472447628308)  \n",
       "35   (0.7244482831172696, 0.009730976281672611)  \n",
       "16   (0.7240820822865546, 0.004915126390816096)  \n",
       "44    (0.7149865519959281, 0.06544871165889138)  \n",
       "29    (0.7131901997927796, 0.06978279895619062)  \n",
       "43    (0.7128032748572108, 0.04512443321485162)  \n",
       "19   (0.7127376991970068, 0.031145413912408052)  \n",
       "1     (0.7111509883437045, 0.01714854886140085)  \n",
       "3    (0.7051900706251587, 0.030344833122833037)  \n",
       "36    (0.6953339488547198, 0.05651379263228147)  \n",
       "28    (0.6946335777405904, 0.03866236793293408)  \n",
       "21   (0.6923358743974918, 0.031623731419079405)  \n",
       "42    (0.6816718199798852, 0.06857344363866094)  \n",
       "40    (0.5967353995343355, 0.40651924219645985)  \n",
       "6     (0.5901083320994287, 0.44444977989347834)  \n",
       "50    (0.5604811113741645, 0.21164702335897254)  \n",
       "7      (0.5583433128950055, 0.4184879967572241)  \n",
       "45      (0.5532532323475241, 0.298001367456875)  \n",
       "8     (0.5396395672780914, 0.28950411573016593)  \n",
       "11     (0.4846529852747148, 0.3763424995914223)  \n",
       "25    (0.35167037298282244, 0.5107919056055533)  \n",
       "38     (-0.6912727789524059, 2.853496489475005)  \n",
       "37     (-0.723689160202128, 2.8372907428439387)  \n",
       "39    (-0.9967229292650994, 2.7188235460399723)  \n",
       "41    (-1.2896601016882936, 2.5542909249228862)  \n",
       "20     (-2.1173733164178294, 3.495496956854777)  \n",
       "23    (-2.1264296474224906, 3.4879366556353473)  \n",
       "5       (-2.127216053661672, 3.487285018549318)  \n",
       "47       (-2.964991845688985, 3.62949448662082)  \n",
       "51                                 (-10.0, 0.0)  \n",
       "52                                 (-10.0, 0.0)  \n",
       "53                                 (-10.0, 0.0)  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>optimizer</th>\n      <th>activation</th>\n      <th>loss</th>\n      <th>layers_shape</th>\n      <th>R2_score, R2_std</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24</th>\n      <td>RMSprop</td>\n      <td>selu</td>\n      <td>mae</td>\n      <td>[13, 6, 1]</td>\n      <td>(0.7971420146721825, 0.023071709866071273)</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>RMSprop</td>\n      <td>relu</td>\n      <td>mae</td>\n      <td>[13, 6, 1]</td>\n      <td>(0.7905222860665662, 0.00666282304786063)</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>SGD</td>\n      <td>selu</td>\n      <td>mse</td>\n      <td>[50, 30, 1]</td>\n      <td>(0.7889368367335818, 0.04818958757485916)</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Adam</td>\n      <td>relu</td>\n      <td>mae</td>\n      <td>[13, 6, 1]</td>\n      <td>(0.7873722926195287, 0.018833544419624967)</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>SGD</td>\n      <td>linear</td>\n      <td>mae</td>\n      <td>[50, 30, 1]</td>\n      <td>(0.7810966945571922, 0.00767961795034878)</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>RMSprop</td>\n      <td>selu</td>\n      <td>mae</td>\n      <td>[13, 8, 5, 3, 1]</td>\n      <td>(0.7775766646973096, 0.0491364572776173)</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Adam</td>\n      <td>linear</td>\n      <td>mae</td>\n      <td>[13, 8, 5, 3, 1]</td>\n      <td>(0.7714796512416612, 0.0037570931662666562)</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>RMSprop</td>\n      <td>linear</td>\n      <td>mae</td>\n      <td>[13, 6, 1]</td>\n      <td>(0.7710631248033433, 0.01189962406137452)</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>RMSprop</td>\n      <td>linear</td>\n      <td>mae</td>\n      <td>[50, 30, 1]</td>\n      <td>(0.7688738094850047, 0.013713705773164435)</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>RMSprop</td>\n      <td>linear</td>\n      <td>mae</td>\n      <td>[13, 8, 5, 3, 1]</td>\n      <td>(0.7687810269385315, 0.010028637921486842)</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Adam</td>\n      <td>linear</td>\n      <td>mae</td>\n      <td>[13, 6, 1]</td>\n      <td>(0.7668250625844604, 0.0038849891009697514)</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Adam</td>\n      <td>linear</td>\n      <td>mae</td>\n      <td>[50, 30, 1]</td>\n      <td>(0.765599709625201, 0.010817962332270531)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Adam</td>\n      <td>relu</td>\n      <td>mae</td>\n      <td>[13, 8, 5, 3, 1]</td>\n      <td>(0.7616890051110026, 0.039455245070751044)</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Adam</td>\n      <td>selu</td>\n      <td>mse</td>\n      <td>[13, 6, 1]</td>\n      <td>(0.7611727642963285, 0.019980520258177387)</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>RMSprop</td>\n      <td>relu</td>\n      <td>mse</td>\n      <td>[50, 30, 1]</td>\n      <td>(0.7584940836070853, 0.025270562807730886)</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>RMSprop</td>\n      <td>selu</td>\n      <td>mse</td>\n      <td>[13, 6, 1]</td>\n      <td>(0.7535051307230377, 0.03212190837906234)</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Adam</td>\n      <td>selu</td>\n      <td>mse</td>\n      <td>[50, 30, 1]</td>\n      <td>(0.7367711127523142, 0.03285601501991992)</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>RMSprop</td>\n      <td>linear</td>\n      <td>mse</td>\n      <td>[13, 6, 1]</td>\n      <td>(0.7300046759942432, 0.013012323415112704)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Adam</td>\n      <td>relu</td>\n      <td>mse</td>\n      <td>[50, 30, 1]</td>\n      <td>(0.7295969412973518, 0.02376057417085283)</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>RMSprop</td>\n      <td>linear</td>\n      <td>mse</td>\n      <td>[50, 30, 1]</td>\n      <td>(0.7278543129695378, 0.02364931628676182)</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Adam</td>\n      <td>linear</td>\n      <td>mse</td>\n      <td>[13, 8, 5, 3, 1]</td>\n      <td>(0.7254046705018851, 0.0027960706866333174)</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Adam</td>\n      <td>linear</td>\n      <td>mse</td>\n      <td>[13, 6, 1]</td>\n      <td>(0.7247156959878326, 0.004706926457964261)</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>SGD</td>\n      <td>linear</td>\n      <td>mae</td>\n      <td>[13, 6, 1]</td>\n      <td>(0.7245256275966104, 0.04845472447628308)</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>RMSprop</td>\n      <td>linear</td>\n      <td>mse</td>\n      <td>[13, 8, 5, 3, 1]</td>\n      <td>(0.7244482831172696, 0.009730976281672611)</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Adam</td>\n      <td>linear</td>\n      <td>mse</td>\n      <td>[50, 30, 1]</td>\n      <td>(0.7240820822865546, 0.004915126390816096)</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>SGD</td>\n      <td>selu</td>\n      <td>mae</td>\n      <td>[13, 8, 5, 3, 1]</td>\n      <td>(0.7149865519959281, 0.06544871165889138)</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>RMSprop</td>\n      <td>selu</td>\n      <td>mse</td>\n      <td>[13, 8, 5, 3, 1]</td>\n      <td>(0.7131901997927796, 0.06978279895619062)</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>SGD</td>\n      <td>selu</td>\n      <td>mae</td>\n      <td>[50, 30, 1]</td>\n      <td>(0.7128032748572108, 0.04512443321485162)</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>RMSprop</td>\n      <td>relu</td>\n      <td>mae</td>\n      <td>[50, 30, 1]</td>\n      <td>(0.7127376991970068, 0.031145413912408052)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Adam</td>\n      <td>relu</td>\n      <td>mae</td>\n      <td>[50, 30, 1]</td>\n      <td>(0.7111509883437045, 0.01714854886140085)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Adam</td>\n      <td>relu</td>\n      <td>mse</td>\n      <td>[13, 6, 1]</td>\n      <td>(0.7051900706251587, 0.030344833122833037)</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>SGD</td>\n      <td>relu</td>\n      <td>mae</td>\n      <td>[13, 6, 1]</td>\n      <td>(0.6953339488547198, 0.05651379263228147)</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>RMSprop</td>\n      <td>selu</td>\n      <td>mse</td>\n      <td>[50, 30, 1]</td>\n      <td>(0.6946335777405904, 0.03866236793293408)</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>RMSprop</td>\n      <td>relu</td>\n      <td>mse</td>\n      <td>[13, 6, 1]</td>\n      <td>(0.6923358743974918, 0.031623731419079405)</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>SGD</td>\n      <td>selu</td>\n      <td>mae</td>\n      <td>[13, 6, 1]</td>\n      <td>(0.6816718199798852, 0.06857344363866094)</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>SGD</td>\n      <td>relu</td>\n      <td>mse</td>\n      <td>[50, 30, 1]</td>\n      <td>(0.5967353995343355, 0.40651924219645985)</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Adam</td>\n      <td>selu</td>\n      <td>mae</td>\n      <td>[13, 6, 1]</td>\n      <td>(0.5901083320994287, 0.44444977989347834)</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>SGD</td>\n      <td>linear</td>\n      <td>mae</td>\n      <td>[13, 8, 5, 3, 1]</td>\n      <td>(0.5604811113741645, 0.21164702335897254)</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Adam</td>\n      <td>selu</td>\n      <td>mae</td>\n      <td>[50, 30, 1]</td>\n      <td>(0.5583433128950055, 0.4184879967572241)</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>SGD</td>\n      <td>selu</td>\n      <td>mse</td>\n      <td>[13, 6, 1]</td>\n      <td>(0.5532532323475241, 0.298001367456875)</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Adam</td>\n      <td>selu</td>\n      <td>mae</td>\n      <td>[13, 8, 5, 3, 1]</td>\n      <td>(0.5396395672780914, 0.28950411573016593)</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Adam</td>\n      <td>selu</td>\n      <td>mse</td>\n      <td>[13, 8, 5, 3, 1]</td>\n      <td>(0.4846529852747148, 0.3763424995914223)</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>RMSprop</td>\n      <td>selu</td>\n      <td>mae</td>\n      <td>[50, 30, 1]</td>\n      <td>(0.35167037298282244, 0.5107919056055533)</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>SGD</td>\n      <td>relu</td>\n      <td>mae</td>\n      <td>[13, 8, 5, 3, 1]</td>\n      <td>(-0.6912727789524059, 2.853496489475005)</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>SGD</td>\n      <td>relu</td>\n      <td>mae</td>\n      <td>[50, 30, 1]</td>\n      <td>(-0.723689160202128, 2.8372907428439387)</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>SGD</td>\n      <td>relu</td>\n      <td>mse</td>\n      <td>[13, 6, 1]</td>\n      <td>(-0.9967229292650994, 2.7188235460399723)</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>SGD</td>\n      <td>relu</td>\n      <td>mse</td>\n      <td>[13, 8, 5, 3, 1]</td>\n      <td>(-1.2896601016882936, 2.5542909249228862)</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>RMSprop</td>\n      <td>relu</td>\n      <td>mae</td>\n      <td>[13, 8, 5, 3, 1]</td>\n      <td>(-2.1173733164178294, 3.495496956854777)</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>RMSprop</td>\n      <td>relu</td>\n      <td>mse</td>\n      <td>[13, 8, 5, 3, 1]</td>\n      <td>(-2.1264296474224906, 3.4879366556353473)</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Adam</td>\n      <td>relu</td>\n      <td>mse</td>\n      <td>[13, 8, 5, 3, 1]</td>\n      <td>(-2.127216053661672, 3.487285018549318)</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>SGD</td>\n      <td>selu</td>\n      <td>mse</td>\n      <td>[13, 8, 5, 3, 1]</td>\n      <td>(-2.964991845688985, 3.62949448662082)</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>SGD</td>\n      <td>linear</td>\n      <td>mse</td>\n      <td>[13, 6, 1]</td>\n      <td>(-10.0, 0.0)</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>SGD</td>\n      <td>linear</td>\n      <td>mse</td>\n      <td>[50, 30, 1]</td>\n      <td>(-10.0, 0.0)</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>SGD</td>\n      <td>linear</td>\n      <td>mse</td>\n      <td>[13, 8, 5, 3, 1]</td>\n      <td>(-10.0, 0.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "columns = ['optimizer', 'activation', 'loss', 'layers_shape', 'R2_score, R2_std']\n",
    "pd.DataFrame(models_result,columns=columns).sort_values('R2_score, R2_std',ascending=False,)"
   ]
  },
  {
   "source": [
    "достаточно разные сети хорошо себя показывают, разные оптимизаторы, активаторы, функции потерь, даже слои весьма разные дают хорошие результаты. Тут достаточно сложно сказать про какуюто структуру что она работает лучше остальных. Некоторые структуры  могут быть неплохи, но переодически расходятся. Если сеть расходилась, то получала R2=-10. И ее средний отрицательный.  По какой то причине видим что SGD linear mse вообще не справился с задачей, не сошелся ни разу. И впринципе SGD проявил себя хуже всех. Чаще всего расходился. Так же мы не использовали регуляризацию, и наши модели всегда работали только 200 эпох. Мы никак не застраховали себя от недообучения и перееобучения, так что имеем сферического коня в вакууме."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Кроме tensorflow.keras.layers.experimental.preprocessing.Normalization ничего не нашел, да и странно искать то что пока не нужно. Полисмотрел многие функции и классы, но даже разобраться что они делают достаточно сложно не понимая всей структуры tonsorflow."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}